{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "852af494-4ada-44c0-b563-4c42a9b76d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     path  symbol_id latex  user_id\n",
      "0  hasy-data/v2-00000.png         31     A       50\n",
      "1  hasy-data/v2-00001.png         31     A       10\n",
      "2  hasy-data/v2-00002.png         31     A       43\n",
      "3  hasy-data/v2-00003.png         31     A       43\n",
      "4  hasy-data/v2-00004.png         31     A     4435\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "csv_filepath = f'C:\\\\New Folder (2)\\\\Handwritting\\\\hasy-data-labels.csv' \n",
    "data = pd.read_csv(csv_filepath)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ca8e0e-ab2b-4f2a-8ee5-4630d9bca930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134586 validated image filenames belonging to 369 classes.\n",
      "Found 33647 validated image filenames belonging to 369 classes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH = 32, 32  \n",
    "BATCH_SIZE = 50\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_data['path'] = train_data['path'].apply(lambda x: os.path.basename(x))\n",
    "val_data['path'] = val_data['path'].apply(lambda x: os.path.basename(x))\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    directory=r'C:\\New Folder (2)\\Handwritting\\hasy-data',  \n",
    "    x_col='path',        \n",
    "    y_col='latex',               \n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='categorical',     \n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_data,\n",
    "    directory=r'C:\\New Folder (2)\\Handwritting\\hasy-data',\n",
    "    x_col='path',  \n",
    "    y_col='latex',   \n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='categorical',  \n",
    "    batch_size=BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff5249f4-c483-424d-93dd-441204174273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(train_data['latex'].unique()) \n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6305624b-f6d7-4649-8c8d-df90436461de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f5a074-63bb-41c1-9017-47e1c185d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05b9c5f3-41b0-4243-ab53-b8bfc731b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2692/2692 [==============================] - 270s 100ms/step - loss: 1.7411 - accuracy: 0.5858 - val_loss: 1.0144 - val_accuracy: 0.7235\n",
      "Epoch 2/10\n",
      "2692/2692 [==============================] - 188s 70ms/step - loss: 0.9394 - accuracy: 0.7323 - val_loss: 0.8876 - val_accuracy: 0.7454\n",
      "Epoch 3/10\n",
      "2692/2692 [==============================] - 199s 74ms/step - loss: 0.8166 - accuracy: 0.7580 - val_loss: 0.8380 - val_accuracy: 0.7561\n",
      "Epoch 4/10\n",
      "2692/2692 [==============================] - 208s 77ms/step - loss: 0.7476 - accuracy: 0.7735 - val_loss: 0.7932 - val_accuracy: 0.7670\n",
      "Epoch 5/10\n",
      "2692/2692 [==============================] - 178s 66ms/step - loss: 0.6991 - accuracy: 0.7850 - val_loss: 0.7849 - val_accuracy: 0.7685\n",
      "Epoch 6/10\n",
      "2692/2692 [==============================] - 146s 54ms/step - loss: 0.6616 - accuracy: 0.7924 - val_loss: 0.7913 - val_accuracy: 0.7734\n",
      "Epoch 7/10\n",
      "2692/2692 [==============================] - 147s 55ms/step - loss: 0.6305 - accuracy: 0.7989 - val_loss: 0.7860 - val_accuracy: 0.7714\n",
      "Epoch 8/10\n",
      "2692/2692 [==============================] - 148s 55ms/step - loss: 0.6028 - accuracy: 0.8064 - val_loss: 0.7715 - val_accuracy: 0.7752\n",
      "Epoch 9/10\n",
      "2692/2692 [==============================] - 151s 56ms/step - loss: 0.5834 - accuracy: 0.8108 - val_loss: 0.7647 - val_accuracy: 0.7797\n",
      "Epoch 10/10\n",
      "2692/2692 [==============================] - 156s 58ms/step - loss: 0.5617 - accuracy: 0.8155 - val_loss: 0.7826 - val_accuracy: 0.7760\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10, \n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(validation_generator)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7432d157-1e24-40b1-95f3-5fefc3a6c1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673/673 [==============================] - 27s 40ms/step - loss: 0.7826 - accuracy: 0.7760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7826281785964966, 0.7760275602340698]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c109f9bf-e8d5-4307-9431-153fed70ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('hasyv2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8fd2fe3-94ad-42ee-9ae3-730b4081c725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673/673 [==============================] - 26s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('hasyv2_model.h5')\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e53ad2db-a853-4694-84e5-40e7d8de7fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5176048e-23, 1.3198396e-23, 2.0305224e-22, ..., 6.6648544e-14,\n",
       "        7.4094546e-15, 4.0830466e-16],\n",
       "       [4.1761381e-14, 2.0787205e-19, 2.5551003e-06, ..., 5.1930581e-08,\n",
       "        3.0672573e-10, 5.4375491e-09],\n",
       "       [6.2188144e-22, 7.5700849e-29, 7.9941614e-16, ..., 9.4362264e-22,\n",
       "        9.6505393e-21, 2.5089376e-17],\n",
       "       ...,\n",
       "       [9.6079816e-18, 3.6499755e-20, 8.7088255e-22, ..., 3.9878859e-13,\n",
       "        7.1496249e-22, 6.6561135e-19],\n",
       "       [1.3976833e-14, 4.4807741e-18, 1.2212664e-10, ..., 7.5727754e-13,\n",
       "        1.3721339e-16, 3.4224709e-07],\n",
       "       [1.7871918e-13, 1.2674995e-17, 1.6522660e-11, ..., 2.0428878e-16,\n",
       "        8.0224577e-11, 1.0949865e-15]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc955ce1-770a-4b1f-a321-1069e6e2f42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
